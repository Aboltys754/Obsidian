Все примеры мы будем тестировать на нашем [тренажере](http://parsinger.ru/html/index1_page_1.html). 

**BeautifulSoup** создает объект из HTML-дерева, по которому мы можем осуществлять необходимую нам навигацию и поиск элементов.

Самые простые и понятные методы, которыми мы пользуемся, когда пишем наши парсеры, это: 

- `**soup.find()**` - этот метод возвращает только первый найденный элемент или узел HTML. Он идеален для ситуаций, когда вам нужно быстро найти конкретный элемент на странице.
- `**soup.find_all()**` - этот метод возвращает **список всех найденных элементов**. Он чрезвычайно полезен, когда необходимо получить все элементы определенного типа. Например, если вы хотите извлечь все ссылки с веб-страницы. Часто `soup.find_all()` используется в комбинации с `soup**.**find()`, чтобы сначала определить определенный родительский элемент, а затем искать внутри него.

## **`soup.find()`** 

Давайте разбираться как работает этот метод на конкретном примере. 

У нас есть [сайт](http://parsinger.ru/html/index1_page_1.html), и мы хотим получить элемент, который содержит атрибут `class='**item**'`

![](https://ucarecdn.com/a24d3657-9524-4aa0-bc1b-04b0be8ab900/)

```python
from bs4 import BeautifulSoup  
import requests  

# Задаем URL-адрес веб-страницы, с которой будем извлекать данные
url = 'https://parsinger.ru/html/index1_page_1.html'

# Выполняем HTTP-запрос к указанному URL-адресу
response = requests.get(url=url)

# Устанавливаем кодировку ответа в 'utf-8', чтобы корректно отображать кириллицу
response.encoding = 'utf-8'

# Создаем объект BeautifulSoup для анализа HTML-кода страницы
# Второй аргумент 'lxml' указывает на используемый парсер
soup = BeautifulSoup(response.text, 'lxml')

# Ищем на странице первый элемент 'div' с классом 'item'
div = soup.find('div', 'item')

# Выводим найденный элемент на экран
print(div)
```

В этом примере мы ищем элемент `<div>` с классом `item`. Метод `soup.find('div', 'item')` ищет на странице первое вхождение элемента `<div>` с классом 'item' и возвращает его. Если такой элемент не будет найден, то метод вернет `None`.

## `soup.find_all()`

Давайте рассмотрим содержимое тега, который мы получили. Видим, что у нас есть все те же элементы HTML. Теперь давайте попробуем извлечь все теги `<li>`. Для этого нам понадобится метод `.find_all()`.

![](https://ucarecdn.com/f0a2691d-72f6-4af5-8e7b-08cc84e1598a/)

```python
from bs4 import BeautifulSoup
import requests

# Задаем URL-адрес веб-страницы, которую хотим проанализировать
url = 'http://parsinger.ru/html/index1_page_1.html'

# Отправляем GET-запрос к указанной странице
response = requests.get(url=url)

# Устанавливаем кодировку ответа сервера в UTF-8, чтобы корректно отображать кириллицу
response.encoding = 'utf-8'

# Преобразуем текст ответа сервера в объект BeautifulSoup для дальнейшего анализа
soup = BeautifulSoup(response.text, 'lxml')

# Ищем на странице первый элемент <div> с классом 'item' и извлекаем из него все вложенные элементы <li>
div = soup.find('div', 'item').find_all('li')

# Выводим на экран список найденных элементов <li>
print(div)
```

Вывод:

```javascript
[<li>Бренд: Jet</li>, <li>Тип: умные часы</li>, <li>Материал корпуса: пластик</li>, <li>Технология экрана: Монохромный</li>]
```

    Обратите внимание, что результатом является список всех элементов `<li>` вместе с их содержимым. Чтобы получить только текстовое содержимое, необходимо убрать теги.  
    Прямо из списка свойство `.text` получить нельзя. Однако, можно легко пройтись по этому списку с помощью цикла `for` и извлечь текст из каждого элемента.

Описание строки `div = soup.find('div', 'item').find_all('li')`:

- `**soup.find('div', 'item')**`: Этот код ищет первый элемент `<div>` с классом `item` на веб-странице. Если такой элемент найден, он возвращается в виде объекта типа `<class 'bs4.element.Tag'>`.
    
- `**soup.find_all('li')**`: Этот метод вызывается для ранее найденного элемента `<div>`. Он ищет и извлекает все вложенные элементы `<li>` внутри этого `<div>`. Возвращаемый результат - это список элементов `<li>`, представленных в виде объектов `<class 'bs4.element.Tag'>`.
    

```python
from bs4 import BeautifulSoup
import requests

# Задаем URL-адрес веб-страницы для парсинга
url = 'http://parsinger.ru/html/index1_page_1.html'

# Отправляем GET-запрос к указанной странице
response = requests.get(url=url)

# Устанавливаем кодировку ответа сервера в UTF-8 для корректного отображения текста на кириллице
response.encoding = 'utf-8'

# Преобразуем текст ответа сервера в объект BeautifulSoup с использованием парсера 'lxml'
soup = BeautifulSoup(response.text, 'lxml')

# Ищем на странице первый элемент <div> с классом 'item' и извлекаем из него все вложенные элементы <li>
div = soup.find('div', 'item').find_all('li')

# Проходимся по списку найденных элементов <li> и выводим их текстовое содержимое
for txt in div:
    print(txt.text)
```

Вывод:

```makefile
Бренд: Jet
Тип: умные часы
Материал корпуса: пластик
Технология экрана: Монохромный
```

Вот и все, мы с вами извлекли данные, которые находились в описании к товару.

![](https://ucarecdn.com/ff152416-e0a5-4a8f-864e-bbfadc40e9ae/)

P.S. Чтобы сократить код и не использовать цикл из двух строк, можно применить [list comprehension](https://pyneng.readthedocs.io/ru/latest/book/08_useful_basics/x_comprehensions.html):

```ini
div = [x.text for x in soup.find('div', 'item').find_all('li')]
```

Это эквивалентно следующему коду:

```applescript
result = []
for txt in div:
    result.append(txt)
```

Такой подход возможен, потому что метод `.find_all('li')` возвращает нам список, состоящий из элементов `li`.